import os
# ç¯å¢ƒé…ç½®ï¼šè§£å†³æœ¬åœ°åº•å±‚çš„å„ç§æ­»é”é—®é¢˜
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
os.environ['OMP_NUM_THREADS'] = '1'

import cv2
import numpy as np
import torch
import torch.nn as nn
import torchvision.models as models
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image
import random # æ–°å¢ï¼šç”¨äºéšæœºæŠ½å–å›¾ç‰‡

# å¼ºè¡Œè®¾ç½® Matplotlib åç«¯ï¼Œé˜²æ­¢ GUI å¼¹çª—å¯¼è‡´ç¨‹åºå‡æ­»
import matplotlib
matplotlib.use('Agg') 
import matplotlib.pyplot as plt


def load_trained_model(weight_path, num_classes=3, device='cpu'):
    """åŠ è½½è®­ç»ƒå¥½çš„ ResNet æ¨¡å‹"""
    print(f"[*] æ­£åœ¨åŠ è½½æ¨¡å‹æƒé‡: {weight_path}")
    model = models.resnet18(weights=None)
    model.fc = nn.Linear(model.fc.in_features, num_classes)
    
    if not os.path.exists(weight_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æƒé‡æ–‡ä»¶ï¼š{weight_path}")
        
    model.load_state_dict(torch.load(weight_path, map_location=device))
    model.to(device)
    model.eval() 
    return model


def generate_batch_cam(model, image_dir, mask_dir, save_path, num_images=5, device='cpu'):
    """è‡ªåŠ¨éšæœºæŠ½å–å¤šå¼ å›¾ç‰‡ï¼Œç”Ÿæˆ Grad-CAM å¹¶æ‹¼æ¥åˆ°ä¸€å¼ å¤§å›¾ä¸Š"""
    print(f"[*] æ­£åœ¨æ‰«æç›®å½•: {image_dir}")
    
    # 1. è·å–ç›®å½•ä¸‹æ‰€æœ‰çš„å›¾ç‰‡æ–‡ä»¶å
    all_files = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]
    
    if len(all_files) == 0:
        raise ValueError(f"åœ¨ {image_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å›¾ç‰‡ï¼")
        
    # å¦‚æœå›¾ç‰‡æ€»æ•°ä¸å¤Ÿ5å¼ ï¼Œå°±æœ‰å¤šå°‘æ‹¿å¤šå°‘
    actual_num = min(num_images, len(all_files))
    
    # 2. éšæœºæŠ½å–æŒ‡å®šæ•°é‡çš„å›¾ç‰‡
    selected_files = random.sample(all_files, actual_num)
    print(f"[*] æˆåŠŸæŠ½å– {actual_num} å¼ å›¾ç‰‡è¿›è¡Œåˆ†æ: \n    {selected_files}")

    # æå–ç‰¹å¾å±‚å¹¶åˆå§‹åŒ– Grad-CAM
    target_layers = [model.layer4[-1]]
    cam = GradCAM(model=model, target_layers=target_layers)

    # 3. åŠ¨æ€åˆ›å»ºå¤§ç”»æ¿ (è¡Œæ•°ä¸ºæŠ½å–å›¾ç‰‡æ•°ï¼Œåˆ—æ•°ä¸º3)
    # æ¯è¡Œé«˜åº¦ä¸º 5ï¼Œå®½åº¦ä¸º 15
    fig, axes = plt.subplots(actual_num, 3, figsize=(15, 5 * actual_num))
    
    # å¦‚æœåªæœ‰1å¼ å›¾ï¼Œaxes ä¼šå˜æˆä¸€ç»´æ•°ç»„ï¼Œä¸ºäº†ä»£ç ç»Ÿä¸€ï¼Œå¼ºè¡Œè½¬ä¸ºäºŒç»´
    if actual_num == 1:
        axes = [axes]

    # 4. å¾ªç¯å¤„ç†æ¯ä¸€å¼ æŠ½åˆ°çš„å›¾ç‰‡
    for i, file_name in enumerate(selected_files):
        img_path = os.path.join(image_dir, file_name)
        mask_path = os.path.join(mask_dir, file_name)

        # -- è¯»å–ä¸é¢„å¤„ç†åŸå›¾ --
        img_gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        if img_gray is None:
            print(f"[-] è¯»å–å¤±è´¥ï¼Œè·³è¿‡: {img_path}")
            continue
            
        img_rgb = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB)
        img_resized = cv2.resize(img_rgb, (224, 224))
        
        img_tensor = torch.from_numpy(img_resized.transpose(2, 0, 1)).float() / 255.0
        input_tensor = img_tensor.unsqueeze(0).to(device)

        # -- ç”Ÿæˆçƒ­åŠ›å›¾ --
        grayscale_cam = cam(input_tensor=input_tensor, targets=None)[0]
        rgb_img_float = img_resized.astype(np.float32) / 255.0
        cam_image = show_cam_on_image(rgb_img_float, grayscale_cam, use_rgb=True)

        # -- è¯»å–çœŸå®æ©ç  --
        truth_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if truth_mask is not None:
            truth_mask = cv2.resize(truth_mask, (224, 224))
        else:
            truth_mask = np.zeros((224, 224), dtype=np.uint8)

        # -- å°†ä¸‰å¼ å›¾ç”»åˆ°å¯¹åº”çš„æ ¼å­é‡Œ --
        axes[i][0].imshow(img_resized)
        axes[i][0].set_title(f'Original: {file_name}')
        axes[i][0].axis('off')
        
        axes[i][1].imshow(cam_image)
        axes[i][1].set_title('AI Search Focus (Grad-CAM)')
        axes[i][1].axis('off')
        
        axes[i][2].imshow(truth_mask, cmap='gray')
        axes[i][2].set_title('Doctor Label (Ground Truth)')
        axes[i][2].axis('off')

    # 5. è°ƒæ•´æ’ç‰ˆå¹¶æ•´ä½“ä¿å­˜
    plt.tight_layout()
    plt.savefig(save_path, bbox_inches='tight', dpi=300)
    plt.close()
    print(f"\nğŸ‰ æ‰¹é‡åˆ†æå®Œæˆï¼èšåˆå¤§å›¾å·²ä¿å­˜è‡³: {save_path}")


if __name__ == '__main__':
    # ================= é…ç½®åŒº =================
    DEVICE = torch.device("cpu")
    WEIGHT_PATH = './baselineResult/resnet18_best_model.pth'
    
    # æˆ‘ä»¬ä¸å†æŒ‡å®šæŸä¸€å¼ å›¾ç‰‡ï¼Œè€Œæ˜¯æŒ‡å®šæ•´ä¸ªæ–‡ä»¶å¤¹çš„è·¯å¾„
    IMAGE_DIR = 'dataset/Test/COVID-19/images/'
    MASK_DIR = 'dataset/Test/COVID-19/infection masks/'
    
    SAVE_RESULT = 'cam_result_3_images.png'
    NUM_IMAGES_TO_TEST = 3  # ä½ å¯ä»¥éšæ—¶æ”¹æˆ 10ï¼Œä»£ç ä¼šè‡ªåŠ¨ç”Ÿæˆæ›´é•¿çš„å¯¹æ¯”å›¾ï¼
    # ==========================================

    # 1. åˆå§‹åŒ–æ¨¡å‹
    resnet_model = load_trained_model(WEIGHT_PATH, num_classes=3, device=DEVICE)
    
    # 2. æ‰§è¡Œæ‰¹é‡è‡ªåŠ¨åŒ–ç”Ÿæˆ
    generate_batch_cam(
        model=resnet_model, 
        image_dir=IMAGE_DIR, 
        mask_dir=MASK_DIR, 
        save_path=SAVE_RESULT, 
        num_images=NUM_IMAGES_TO_TEST,
        device=DEVICE
    )