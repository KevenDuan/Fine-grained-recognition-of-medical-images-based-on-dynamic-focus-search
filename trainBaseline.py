import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models
from torch.utils.data import DataLoader
from dataset import COVIDFocusDataset 
from tqdm import tqdm
import matplotlib.pyplot as plt  # æ–°å¢ï¼šå¯¼å…¥ç”»å›¾åº“

if __name__ == '__main__':
    data_dir = './dataset'

    print("æ­£åœ¨åŠ è½½è®­ç»ƒé›†å’ŒéªŒè¯é›†...")
    train_dataset = COVIDFocusDataset(base_dir=data_dir, split='Train', target_size=(224, 224))
    val_dataset = COVIDFocusDataset(base_dir=data_dir, split='Val', target_size=(224, 224))

    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=8)
    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=8)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"æ•°æ®åŠ è½½å®Œæˆï¼å½“å‰è®¡ç®—è®¾å¤‡: {device}")

    # è¿ç§»å­¦ä¹ ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„ ResNet-18 æ¨¡å‹
    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
    model.fc = nn.Linear(model.fc.in_features, 3)
    model = model.to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.0001)

    best_val_acc = 0.0
    
    # ================= æ–°å¢ï¼šå‡†å¤‡è®°å½•æ•°æ®çš„â€œå°æœ¬æœ¬â€ =================
    history_train_loss = []
    history_val_loss = []
    history_val_acc = []
    
    num_epochs = 30
    for epoch in range(num_epochs):
        print(f"\n======== Epoch {epoch+1}/{num_epochs} ========")
        
        # ------------------ è®­ç»ƒé˜¶æ®µ ------------------
        model.train()
        running_loss = 0.0
        
        pbar_train = tqdm(train_loader, desc="[è®­ç»ƒé˜¶æ®µ]", unit="batch")
        for images, masks, labels in pbar_train:
            images, labels = images.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item()
            pbar_train.set_postfix({'Train Loss': f"{running_loss / (pbar_train.n + 1):.4f}"})

        # è®¡ç®—æœ¬è½®çš„å¹³å‡è®­ç»ƒè¯¯å·®ï¼Œå¹¶è®°å…¥å°æœ¬æœ¬
        avg_train_loss = running_loss / len(train_loader)
        history_train_loss.append(avg_train_loss)

        # ------------------ éªŒè¯é˜¶æ®µ ------------------
        model.eval() 
        val_loss = 0.0
        correct = 0   
        total = 0     
        
        with torch.no_grad():
            pbar_val = tqdm(val_loader, desc="[éªŒè¯é˜¶æ®µ]", unit="batch")
            for images, masks, labels in pbar_val:
                images, labels = images.to(device), labels.to(device)
                
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                
                _, predicted = torch.max(outputs.data, 1)
                
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                
        # è®¡ç®—æœ¬è½®çš„éªŒè¯è¯¯å·®å’Œå‡†ç¡®ç‡ï¼Œå¹¶è®°å…¥å°æœ¬æœ¬
        epoch_acc = 100 * correct / total
        avg_val_loss = val_loss / len(val_loader)
        
        history_val_loss.append(avg_val_loss)
        history_val_acc.append(epoch_acc)
        
        print(f"ğŸ‘‰ æœ¬è½®æˆç»©å•: Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | å‡†ç¡®ç‡: {epoch_acc:.2f}%")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if epoch_acc > best_val_acc:
            best_val_acc = epoch_acc
            torch.save(model.state_dict(), 'resnet18_best_model.pth')
            print(f"ğŸŒŸ æ¨¡å‹å·²ä¿å­˜è‡³ resnet18_best_model.pth, å‡†ç¡®ç‡: {best_val_acc:.2f}%")

    # ================= æ–°å¢ï¼šå…¨éƒ¨è·‘å®Œåï¼Œç»˜åˆ¶å¹¶ä¿å­˜è®­ç»ƒæ›²çº¿å›¾ =================
    print("\nè®­ç»ƒç»“æŸï¼Œæ­£åœ¨ç»˜åˆ¶è®­ç»ƒæ›²çº¿å›¾...")
    
    # è®¾ç½®ç”»å¸ƒå¤§å°ï¼Œ1è¡Œ2åˆ—çš„å¹¶æ’å›¾
    plt.figure(figsize=(12, 5))
    
    # ç”»ç¬¬ä¸€å¼ å›¾ï¼šLoss æ›²çº¿ (å¯¹æ¯” Train å’Œ Val)
    plt.subplot(1, 2, 1)
    plt.plot(range(1, num_epochs + 1), history_train_loss, label='Train Loss', marker='o')
    plt.plot(range(1, num_epochs + 1), history_val_loss, label='Validation Loss', marker='x')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    
    # ç”»ç¬¬äºŒå¼ å›¾ï¼šAccuracy æ›²çº¿
    plt.subplot(1, 2, 2)
    plt.plot(range(1, num_epochs + 1), history_val_acc, label='Validation Accuracy', color='green', marker='s')
    plt.title('Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy (%)')
    plt.legend()
    plt.grid(True)
    
    # è°ƒæ•´å¸ƒå±€å¹¶ä¿å­˜å›¾ç‰‡
    plt.tight_layout()
    plt.savefig('training_curve.png', dpi=300) # dpi=300 ä¿è¯å›¾ç‰‡æ”¾åœ¨è®ºæ–‡é‡Œè¶³å¤Ÿé«˜æ¸…
    print("âœ… æ›²çº¿å›¾å·²æˆåŠŸä¿å­˜ä¸º training_curve.png")